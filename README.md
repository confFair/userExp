# The Necessity of MBFair

We further aimed to study the necessity for an automated approach that analyses UML models to detect discrimination.
We aimed at investigating the following hypotheses:

* H1: Analysts overlook true-positive discrimination when they analyze UML models manually.
* H2: The result of detecting discrimination manually has a low degree of reliability.

We studied the hypotheses H1 and H2 in a user experiment with 13 participants. specifically, 10 master students, and 3 researchers. In this page we present the artifacts of user experiment. The artifacts include the questionnaire, the  cheatsheet and the results of the questionnaire.

# Recources

* **The cheatsheet:** [cheatsheet](https://github.com/mbfairness/userExp/blob/main/cheatsheet-Fairness-specifications.pdf)
* **The questionair:** [questionair](https://github.com/mbfairness/userExp/blob/main/Survey_%20Fairness%20Analysis%20based%20on%20Software%20Design%20Models%20-%20Google%20Forms.pdf)
* **The results of the questionnaire:** [results](https://github.com/mbfairness/userExp/blob/main/Result-Survey_%20Fairness%20Analysis%20based%20on%20Software%20Design%20Models.xlsx)

